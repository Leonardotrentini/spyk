# üï∑Ô∏è Sistema de Scraping Manual - Facebook Ads Library

Sistema completo de scraping da Facebook Ads Library usando Playwright, sem depender da API da Meta.

## üìã Estrutura do Projeto

```
src/
‚îú‚îÄ‚îÄ config/           # Configura√ß√µes (Supabase, headless, etc.)
‚îú‚îÄ‚îÄ scrapers/         # Scrapers Playwright
‚îÇ   ‚îú‚îÄ‚îÄ adLibrarySearch.ts    # Busca por keyword
‚îÇ   ‚îî‚îÄ‚îÄ adLibraryPage.ts      # Scraping completo de uma p√°gina
‚îú‚îÄ‚îÄ services/         # L√≥gica de neg√≥cio
‚îÇ   ‚îú‚îÄ‚îÄ aggregation.ts        # Agrega√ß√£o de hits por p√°gina
‚îÇ   ‚îî‚îÄ‚îÄ offerRule.ts          # Regra de oferta v√°lida
‚îú‚îÄ‚îÄ db/               # Banco de dados
‚îÇ   ‚îú‚îÄ‚îÄ schema.sql            # Schema do Supabase
‚îÇ   ‚îú‚îÄ‚îÄ supabaseClient.ts     # Cliente Supabase
‚îÇ   ‚îî‚îÄ‚îÄ repositories/         # Reposit√≥rios de dados
‚îÇ       ‚îú‚îÄ‚îÄ pages.ts
‚îÇ       ‚îú‚îÄ‚îÄ ads.ts
‚îÇ       ‚îî‚îÄ‚îÄ searchHits.ts
‚îî‚îÄ‚îÄ cli/              # CLI principal
    ‚îî‚îÄ‚îÄ runKeywords.ts
```

## üöÄ Instala√ß√£o

### 1. Instalar depend√™ncias

```bash
npm install
# ou
pnpm install
```

### 2. Instalar Playwright Chromium

```bash
npm run scrape:install
# ou
npx playwright install chromium
```

### 3. Configurar vari√°veis de ambiente

Crie um arquivo `.env.local` na raiz do projeto:

```env
SUPABASE_URL=https://seu-projeto.supabase.co
SUPABASE_SERVICE_ROLE_KEY=sua-service-role-key
ADLIB_SCRAPER_HEADLESS=true  # false para ver o navegador
DEFAULT_COUNTRY=BR
```

### 4. Criar tabelas no Supabase

Execute o arquivo `src/db/schema.sql` no SQL Editor do Supabase.

## üìù Como Usar

### Op√ß√£o 1: Via arquivo JSON

Crie um arquivo `keywords.json`:

```json
{
  "keywords": [
    "infoproduto",
    "marketing digital",
    "curso online"
  ],
  "country": "BR"
}
```

Execute:

```bash
npm run scrape:keywords -- --file keywords.json
```

### Op√ß√£o 2: Via argumentos da linha de comando

```bash
npm run scrape:keywords -- --keywords "infoproduto,marketing digital,curso online" --country BR
```

## üîÑ Fluxo de Execu√ß√£o

1. **FASE 1: Busca por Keywords**
   - Para cada keyword, faz scraping da Ads Library
   - Coleta `pageId`, `pageName`, `adId` de cada an√∫ncio encontrado
   - Salva resultados em `page_search_hits`

2. **FASE 2: Agrega√ß√£o**
   - Agrupa hits por `pageId` + `country`
   - Calcula `hitsFromSearch` (total de an√∫ncios encontrados)
   - Salva/atualiza em `pages`

3. **FASE 3: Filtro de Candidatos**
   - Filtra p√°ginas com `hitsFromSearch >= 10`

4. **FASE 4: Scraping Completo**
   - Para cada p√°gina candidata:
     - Abre `view_all_page_id` na Ads Library
     - Faz scroll infinito para carregar todos os an√∫ncios
     - Extrai: `adId`, `text`, `headline`, `cta`, `mediaType`, `mediaUrls`, `destinationUrls`, `startedRunningOn`
     - Calcula `startedRunningDaysAgo`
     - Salva an√∫ncios em `ads`
     - Avalia regra de oferta v√°lida

5. **FASE 5: Regra de Oferta V√°lida**
   - `totalActiveAds >= 10`
   - E existe pelo menos 1 an√∫ncio com `startedRunningDaysAgo >= 7`
   - Atualiza `has_offer_by_rule` em `pages`

6. **FASE 6: Resumo**
   - Exibe tabela no console com p√°ginas que passaram na regra
   - Salva JSON em `output/latest_pages_with_offers.json`

## üìä Schema do Banco

### Tabela `pages`
- `page_id` (unique)
- `page_name`
- `country`
- `estimated_active_ads_from_search`
- `total_active_ads`
- `has_ad_older_than_7_days`
- `has_offer_by_rule`
- `first_seen_at`, `last_seen_at`, `last_audit_at`

### Tabela `page_search_hits`
- `keyword`
- `country`
- `page_id`
- `page_name`
- `ads_count_for_keyword`
- `scraped_at`

### Tabela `ads`
- `page_id`
- `ad_id`
- `text`, `headline`, `cta`
- `media_type` (image | video | carousel | unknown)
- `media_urls` (JSONB)
- `destination_urls` (JSONB)
- `started_running_on`
- `started_running_days_ago`
- `scraped_at`

## ‚öôÔ∏è Configura√ß√µes

### Modo Headless

Por padr√£o, o scraper roda em modo headless (sem interface gr√°fica). Para ver o navegador:

```env
ADLIB_SCRAPER_HEADLESS=false
```

### Delays

O scraper inclui delays autom√°ticos:
- 2 segundos entre scrolls
- 2 segundos entre keywords
- 3 segundos entre p√°ginas

Isso evita sobrecarregar a Ads Library.

## üêõ Troubleshooting

### Erro: "Playwright n√£o encontrado"

Execute:
```bash
npm run scrape:install
```

### Erro: "SUPABASE_URL n√£o configurado"

Verifique se o arquivo `.env.local` existe e tem as vari√°veis corretas.

### Erro: "Tabela n√£o existe"

Execute `src/db/schema.sql` no SQL Editor do Supabase.

### Nenhum an√∫ncio encontrado

- Verifique se as keywords est√£o corretas
- Tente com `headless=false` para ver o que est√° acontecendo
- A Ads Library pode ter mudado o layout (ajuste os seletores em `adLibrarySearch.ts` e `adLibraryPage.ts`)

## üìù Notas Importantes

- **M√°ximo de 20 keywords** por execu√ß√£o
- O scraping pode demorar bastante (v√°rios minutos) dependendo do n√∫mero de keywords e p√°ginas
- Os seletores CSS podem precisar de ajustes se o Facebook mudar o layout
- Use com modera√ß√£o para n√£o sobrecarregar a Ads Library

## üîß Ajustando Seletores

Se o Facebook mudar o layout, voc√™ precisar√° ajustar os seletores em:

- `src/scrapers/adLibrarySearch.ts` (linha ~56)
- `src/scrapers/adLibraryPage.ts` (linha ~77)

Use o modo `headless=false` para inspecionar o DOM e ajustar os seletores.

